{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG WRITER DIMENSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at full dataframe -> print(df) <br>\n",
    "To look at seperated dataframe -> print(dfs)/print(dict['df_(dataframe number)']) <br>\n",
    "To look at rank scores -> print(rank_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension Type:\n",
      "File Format: \n",
      "Schemas: \n",
      "Partition: \n",
      "./logs/avro/100M_st_horizontal.txt\n",
      "./logs/avro/100M_vt_horizontal.txt\n",
      "./logs/avro/100M_pt_horizontal.txt\n",
      "./logs/avro/100M_extvt_horizontal.txt\n",
      "./logs/avro/100M_wpt_horizontal.txt\n",
      "./logs/csv/100M_st_horizontal.txt\n",
      "./logs/csv/100M_vt_horizontal.txt\n",
      "./logs/csv/100M_pt_horizontal.txt\n",
      "./logs/csv/100M_extvt_horizontal.txt\n",
      "./logs/csv/100M_wpt_horizontal.txt\n",
      "./logs/orc/100M_st_horizontal.txt\n",
      "./logs/orc/100M_vt_horizontal.txt\n",
      "./logs/orc/100M_pt_horizontal.txt\n",
      "./logs/orc/100M_extvt_horizontal.txt\n",
      "./logs/orc/100M_wpt_horizontal.txt\n",
      "./logs/parquet/100M_st_horizontal.txt\n",
      "./logs/parquet/100M_vt_horizontal.txt\n",
      "./logs/parquet/100M_pt_horizontal.txt\n",
      "./logs/parquet/100M_extvt_horizontal.txt\n",
      "./logs/parquet/100M_wpt_horizontal.txt\n",
      "./logs/avro/100M_st_subject.txt\n",
      "./logs/avro/100M_vt_subject.txt\n",
      "./logs/avro/100M_pt_subject.txt\n",
      "./logs/avro/100M_extvt_subject.txt\n",
      "./logs/avro/100M_wpt_subject.txt\n",
      "./logs/csv/100M_st_subject.txt\n",
      "./logs/csv/100M_vt_subject.txt\n",
      "./logs/csv/100M_pt_subject.txt\n",
      "./logs/csv/100M_extvt_subject.txt\n",
      "./logs/csv/100M_wpt_subject.txt\n",
      "./logs/orc/100M_st_subject.txt\n",
      "./logs/orc/100M_vt_subject.txt\n",
      "./logs/orc/100M_pt_subject.txt\n",
      "./logs/orc/100M_extvt_subject.txt\n",
      "./logs/orc/100M_wpt_subject.txt\n",
      "./logs/parquet/100M_st_subject.txt\n",
      "./logs/parquet/100M_vt_subject.txt\n",
      "./logs/parquet/100M_pt_subject.txt\n",
      "./logs/parquet/100M_extvt_subject.txt\n",
      "./logs/parquet/100M_wpt_subject.txt\n",
      "./logs/avro/100M_st_predicate.txt\n",
      "./logs/avro/100M_vt_predicate.txt\n",
      "./logs/avro/100M_pt_predicate.txt\n",
      "./logs/avro/100M_extvt_predicate.txt\n",
      "./logs/avro/100M_wpt_predicate.txt\n",
      "./logs/csv/100M_st_predicate.txt\n",
      "./logs/csv/100M_vt_predicate.txt\n",
      "./logs/csv/100M_pt_predicate.txt\n",
      "./logs/csv/100M_extvt_predicate.txt\n",
      "./logs/csv/100M_wpt_predicate.txt\n",
      "./logs/orc/100M_st_predicate.txt\n",
      "./logs/orc/100M_vt_predicate.txt\n",
      "./logs/orc/100M_pt_predicate.txt\n",
      "./logs/orc/100M_extvt_predicate.txt\n",
      "./logs/orc/100M_wpt_predicate.txt\n",
      "./logs/parquet/100M_st_predicate.txt\n",
      "./logs/parquet/100M_vt_predicate.txt\n",
      "./logs/parquet/100M_pt_predicate.txt\n",
      "./logs/parquet/100M_extvt_predicate.txt\n",
      "./logs/parquet/100M_wpt_predicate.txt\n"
     ]
    }
   ],
   "source": [
    "# WRITING THE LOG\n",
    "import pandas as pd\n",
    "\n",
    "# file_format = ['csv', 'avro', 'parquet', 'orc']\n",
    "# schemas = ['st','vt', 'pt', 'extvt', 'wpt']\n",
    "# partition = ['horizontal','predicate', 'subject']\n",
    "\n",
    "print('Dimension Type:')\n",
    "dimension = input()\n",
    "\n",
    "file_format = []\n",
    "schemas = []\n",
    "partition = []\n",
    "\n",
    "# take file format input\n",
    "print(\"File Format: \")\n",
    "while True:\n",
    "    line = input()\n",
    "    if line:\n",
    "        file_format.append(line)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# take schemas input\n",
    "print(\"Schemas: \")\n",
    "while True:\n",
    "    line = input()\n",
    "    if line:\n",
    "        schemas.append(line)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# take partition input\n",
    "print(\"Partition: \")\n",
    "while True:\n",
    "    line = input()\n",
    "    if line:\n",
    "        partition.append(line)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "if dimension == 'storage': \n",
    "    idx = []\n",
    "    li=[]\n",
    "    # READ LOG - STORAGE FORMAT\n",
    "    for i in schemas:\n",
    "        for j in partition:\n",
    "            for k in file_format:\n",
    "                # check folder\n",
    "                print(f'./logs/{k}/100M_{i}_{j}.txt')\n",
    "\n",
    "                df = pd.read_csv(f'./logs/{k}/100M_{i}_{j}.txt',sep = ',', header = None)\n",
    "                df = df.fillna(0)\n",
    "                avg = df.mean(axis = 0)\n",
    "                li.append(avg)\n",
    "                idx.append(k + f\"_{i}_{j}\")\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(li, index = [idx])\n",
    "    df = df.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 1)\n",
    "    df = df.fillna(5000)\n",
    "    # split dataframe\n",
    "    dict = {}\n",
    "    count = 0\n",
    "    loop = len(file_format)\n",
    "    dfs = []\n",
    "    for i in range(int(len(partition) * len(file_format) * len(schemas) / len(file_format))):\n",
    "        dict['df_{}'.format(i)] = df[count:loop]\n",
    "        count = loop\n",
    "        loop = loop+len(file_format)\n",
    "        dfs.append(dict[f'df_{i}'])\n",
    "\n",
    "    # CREATE RANK OCCURENCES\n",
    "    import scipy.stats as ss\n",
    "    import numpy as np\n",
    "\n",
    "    rank_dataframe = []\n",
    "\n",
    "    for x in dfs:\n",
    "        df_ranks = x.T\n",
    "        column_names = df_ranks.columns.to_numpy().tolist()\n",
    "        column_names = [column_names for column_names, in column_names]\n",
    "        \n",
    "        df_ranks_occurences = []\n",
    "        for index, row in df_ranks.iterrows():\n",
    "            df_ranks_occurences.append(ss.rankdata(row, method = 'max'))\n",
    "\n",
    "        df_ranks_occurences = pd.DataFrame(df_ranks_occurences)\n",
    "\n",
    "        df_transpose = df_ranks_occurences.transpose()\n",
    "\n",
    "        rank_table = []\n",
    "        for index, row in df_transpose.iterrows():\n",
    "            result_row = np.zeros(len(df_transpose.index))\n",
    "            for i in range(len(row)):\n",
    "                result_row[int(row[i])-1] +=1\n",
    "            rank_table.append(result_row)\n",
    "\n",
    "        rank_table = pd.DataFrame(rank_table)\n",
    "        rank_table = rank_table.set_axis(column_names, axis = 'index')\n",
    "        rank_table = rank_table.set_axis([i+1 for i in range(len(column_names))], axis='columns')\n",
    "\n",
    "        # CREATE R SCORE\n",
    "        q = 11\n",
    "        d = len(rank_table.index)\n",
    "\n",
    "        rank_score = []\n",
    "        for index, row in rank_table.iterrows():\n",
    "            s = 0\n",
    "            for r in range(d):  \n",
    "                s = s + (row[r+1]*(d-(r+1)) / (q*(d-1)) )\n",
    "            rank_score.append(s)\n",
    "        rank_score = pd.DataFrame(rank_score)\n",
    "        rank_score = rank_score.set_axis(column_names, axis = 'index')\n",
    "        rank_score = rank_score.set_axis(['Result'], axis='columns')\n",
    "        rank_score = pd.concat([rank_table, rank_score], axis = 1)\n",
    "        rank_dataframe.append(rank_score)\n",
    "####################################################################################################\n",
    "elif dimension == 'schema':\n",
    "    idx = []\n",
    "    li=[]\n",
    "    # READ LOG - STORAGE FORMAT\n",
    "    for j in partition:\n",
    "        for k in file_format:\n",
    "            for i in schemas:\n",
    "                # check folder\n",
    "                print(f'./logs/{k}/100M_{i}_{j}.txt')\n",
    "\n",
    "                df = pd.read_csv(f'./logs/{k}/100M_{i}_{j}.txt',sep = ',', header = None)\n",
    "                df = df.fillna(0)\n",
    "                avg = df.mean(axis = 0)\n",
    "                li.append(avg)\n",
    "                idx.append(k + f\"_{i}_{j}\")\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(li, index = [idx])\n",
    "    df = df.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 1)\n",
    "    df = df.fillna(5000)\n",
    "    # split dataframe\n",
    "    dict = {}\n",
    "    count = 0\n",
    "    loop = len(schemas)\n",
    "    dfs = []\n",
    "    for i in range(int(len(partition) * len(file_format) * len(schemas) / len(schemas))):\n",
    "        dict['df_{}'.format(i)] = df[count:loop]\n",
    "        count = loop\n",
    "        loop = loop+len(schemas)\n",
    "        dfs.append(dict[f'df_{i}'])\n",
    "\n",
    "    # CREATE RANK OCCURENCES\n",
    "    import scipy.stats as ss\n",
    "    import numpy as np\n",
    "\n",
    "    rank_dataframe = []\n",
    "\n",
    "    for x in dfs:\n",
    "        df_ranks = x.T\n",
    "        column_names = df_ranks.columns.to_numpy().tolist()\n",
    "        column_names = [column_names for column_names, in column_names]\n",
    "        \n",
    "        df_ranks_occurences = []\n",
    "        for index, row in df_ranks.iterrows():\n",
    "            df_ranks_occurences.append(ss.rankdata(row, method = 'max'))\n",
    "\n",
    "        df_ranks_occurences = pd.DataFrame(df_ranks_occurences)\n",
    "\n",
    "        df_transpose = df_ranks_occurences.transpose()\n",
    "\n",
    "        rank_table = []\n",
    "        for index, row in df_transpose.iterrows():\n",
    "            result_row = np.zeros(len(df_transpose.index))\n",
    "            for i in range(len(row)):\n",
    "                result_row[int(row[i])-1] +=1\n",
    "            rank_table.append(result_row)\n",
    "\n",
    "        rank_table = pd.DataFrame(rank_table)\n",
    "        rank_table = rank_table.set_axis(column_names, axis = 'index')\n",
    "        rank_table = rank_table.set_axis([i+1 for i in range(len(column_names))], axis='columns')\n",
    "\n",
    "        # CREATE R SCORE\n",
    "        q = 11\n",
    "        d = len(rank_table.index)\n",
    "\n",
    "        rank_score = []\n",
    "        for index, row in rank_table.iterrows():\n",
    "            s = 0\n",
    "            for r in range(d):  \n",
    "                s = s + (row[r+1]*(d-(r+1)) / (q*(d-1)) )\n",
    "            rank_score.append(s)\n",
    "        rank_score = pd.DataFrame(rank_score)\n",
    "        rank_score = rank_score.set_axis(column_names, axis = 'index')\n",
    "        rank_score = rank_score.set_axis(['Result'], axis='columns')\n",
    "        rank_score = pd.concat([rank_table, rank_score], axis = 1)\n",
    "        rank_dataframe.append(rank_score)\n",
    "########################################################################################################\n",
    "elif dimension == 'partition':\n",
    "    idx = []\n",
    "    li=[]\n",
    "    # READ LOG - STORAGE FORMAT\n",
    "    for i in schemas:\n",
    "        for k in file_format:\n",
    "            for j in partition:\n",
    "                # check folder\n",
    "                print(f'./logs/{k}/100M_{i}_{j}.txt')\n",
    "\n",
    "                df = pd.read_csv(f'./logs/{k}/100M_{i}_{j}.txt',sep = ',', header = None)\n",
    "                df = df.fillna(0)\n",
    "                avg = df.mean(axis = 0)\n",
    "                li.append(avg)\n",
    "                idx.append(k + f\"_{i}_{j}\")\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(li, index = [idx])\n",
    "    df = df.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 1)\n",
    "    df = df.fillna(5000)\n",
    "    # split dataframe\n",
    "    dict = {}\n",
    "    count = 0\n",
    "    loop = len(partition)\n",
    "    dfs = []\n",
    "    for i in range(int(len(partition) * len(file_format) * len(schemas) / len(partition))):\n",
    "        dict['df_{}'.format(i)] = df[count:loop]\n",
    "        count = loop\n",
    "        loop = loop+len(partition)\n",
    "        dfs.append(dict[f'df_{i}'])\n",
    "\n",
    "    # CREATE RANK OCCURENCES\n",
    "    import scipy.stats as ss\n",
    "    import numpy as np\n",
    "\n",
    "    rank_dataframe = []\n",
    "\n",
    "    for x in dfs:\n",
    "        df_ranks = x.T\n",
    "        column_names = df_ranks.columns.to_numpy().tolist()\n",
    "        column_names = [column_names for column_names, in column_names]\n",
    "        \n",
    "        df_ranks_occurences = []\n",
    "        for index, row in df_ranks.iterrows():\n",
    "            df_ranks_occurences.append(ss.rankdata(row, method = 'max'))\n",
    "\n",
    "        df_ranks_occurences = pd.DataFrame(df_ranks_occurences)\n",
    "\n",
    "        df_transpose = df_ranks_occurences.transpose()\n",
    "\n",
    "        rank_table = []\n",
    "        for index, row in df_transpose.iterrows():\n",
    "            result_row = np.zeros(len(df_transpose.index))\n",
    "            for i in range(len(row)):\n",
    "                result_row[int(row[i])-1] +=1\n",
    "            rank_table.append(result_row)\n",
    "\n",
    "        rank_table = pd.DataFrame(rank_table)\n",
    "        rank_table = rank_table.set_axis(column_names, axis = 'index')\n",
    "        rank_table = rank_table.set_axis([i+1 for i in range(len(column_names))], axis='columns')\n",
    "\n",
    "        # CREATE R SCORE\n",
    "        q = 11\n",
    "        d = len(rank_table.index)\n",
    "\n",
    "        rank_score = []\n",
    "        for index, row in rank_table.iterrows():\n",
    "            s = 0\n",
    "            for r in range(d):  \n",
    "                s = s + (row[r+1]*(d-(r+1)) / (q*(d-1)) )\n",
    "            rank_score.append(s)\n",
    "        rank_score = pd.DataFrame(rank_score)\n",
    "        rank_score = rank_score.set_axis(column_names, axis = 'index')\n",
    "        rank_score = rank_score.set_axis(['Result'], axis='columns')\n",
    "        rank_score = pd.concat([rank_table, rank_score], axis = 1)\n",
    "        rank_dataframe.append(rank_score)\n",
    "\n",
    "else:\n",
    "    print(\"choose 'storage' or 'partition' or 'schema' dimension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to excel for better view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create excel sheet\n",
    "excel_table = dfs+rank_dataframe\n",
    "xlwriter = pd.ExcelWriter('~/Desktop/rank_table.xlsx', engine='xlsxwriter')\n",
    "row = 0\n",
    "for dataframe in excel_table:\n",
    "        dataframe.to_excel(xlwriter, sheet_name = 'schema_format_100M', startrow = row, startcol = 0)\n",
    "        row = row + len(dataframe.index) + 2 \n",
    "xlwriter.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFORMANCE PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ranks_scores = pd.concat(rank_dataframe, axis = 0)\n",
    "full_ranks_scores = full_ranks_scores['Result']\n",
    "best_scores = full_ranks_scores.nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_ranks = []\n",
    "df = df.T\n",
    "for index, row in df.iterrows():\n",
    "    df_full_ranks.append(ss.rankdata(row, method = 'max'))\n",
    "\n",
    "df_full_ranks = pd.DataFrame(df_full_ranks)\n",
    "df_full_ranks = df_full_ranks.T\n",
    "df_full_ranks = df_full_ranks.set_axis(df.columns, axis = 'index') #configurations\n",
    "df_full_ranks = df_full_ranks.set_axis([i+1 for i in range(len(df.index))], axis='columns') #query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avro_vt_predicate          0.772727\n",
       "csv_vt_predicate           0.750000\n",
       "parquet_extvt_predicate    0.750000\n",
       "orc_extvt_predicate        0.727273\n",
       "avro_pt_subject            0.704545\n",
       "Name: Result, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         1   2   3   4   5   6   7   8   9   10  11\n",
      "avro_vt_predicate        20  32  17  55  16  23  10  43  54  18   7\n",
      "csv_vt_predicate          7  39  36  46  27  24   9  34  49  26  13\n",
      "parquet_extvt_predicate  22  10  14  42  21  20  44  30  28  23  60\n",
      "orc_extvt_predicate      30  13  11  43  28  28  54  27  18  17  60\n",
      "avro_pt_subject          42  35   6  16  17  10  19  10  17  30  22\n"
     ]
    }
   ],
   "source": [
    "best_scores = best_scores.index.to_numpy().tolist()\n",
    "criteria_table = df_full_ranks.loc[best_scores]\n",
    "print(criteria_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avro_vt_predicate</th>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv_vt_predicate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parquet_extvt_predicate</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orc_extvt_predicate</th>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avro_pt_subject</th>\n",
       "      <td>42.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           1     2     3   4   5     6     7     8   9   10  \\\n",
       "avro_vt_predicate        20.0  32.0  17.0  55  16  23.0   NaN  43.0  54  18   \n",
       "csv_vt_predicate          NaN  39.0  36.0  46  27  24.0   NaN  34.0  49  26   \n",
       "parquet_extvt_predicate  22.0   NaN   NaN  42  21  20.0  44.0  30.0  28  23   \n",
       "orc_extvt_predicate      30.0   NaN   NaN  43  28  28.0  54.0  27.0  18  17   \n",
       "avro_pt_subject          42.0  35.0   NaN  16  17   NaN  19.0   NaN  17  30   \n",
       "\n",
       "                           11  \n",
       "avro_vt_predicate         NaN  \n",
       "csv_vt_predicate          NaN  \n",
       "parquet_extvt_predicate  60.0  \n",
       "orc_extvt_predicate      60.0  \n",
       "avro_pt_subject          22.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = criteria_table[criteria_table > 15]\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avro_vt_predicate          9\n",
       "csv_vt_predicate           8\n",
       "parquet_extvt_predicate    9\n",
       "orc_extvt_predicate        9\n",
       "avro_pt_subject            8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing1 = testing.count(axis=1)\n",
    "testing1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = testing1.mean(axis = 0)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = testing1.sum(axis = 0)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21818181818181814"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (sum/55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f0c97177db804969054b15d96dba8bf61465ec3c27ea998f6ffcddfd8bb05c1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
