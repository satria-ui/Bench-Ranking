{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG WRITER DIMENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     csv_st_horizontal  avro_st_horizontal  parquet_st_horizontal  \\\n",
       " Q1           49.608458           34.927520              24.956528   \n",
       " Q2          168.670828           79.977400              57.742420   \n",
       " Q3           32.021346           12.211584               6.941551   \n",
       " Q4          232.845823          175.171868             169.987462   \n",
       " Q5           93.884036           44.462770              33.468086   \n",
       " Q6           98.338989           52.109702              47.166969   \n",
       " Q7          146.522541           94.447627              74.262720   \n",
       " Q8          172.249262          130.898701             131.645367   \n",
       " Q9           71.971304           41.511777              33.855555   \n",
       " Q10          28.628432           10.192575               4.247113   \n",
       " Q11          14.293006            5.348119               1.679916   \n",
       " \n",
       "      orc_st_horizontal  \n",
       " Q1           27.277521  \n",
       " Q2           58.011053  \n",
       " Q3            6.502544  \n",
       " Q4          171.147992  \n",
       " Q5           32.488883  \n",
       " Q6           43.339918  \n",
       " Q7           72.468041  \n",
       " Q8          127.247422  \n",
       " Q9           31.657362  \n",
       " Q10           2.437929  \n",
       " Q11           1.397683  ,\n",
       "      csv_st_predicate  avro_st_predicate  parquet_st_predicate  \\\n",
       " Q1          46.328714          34.304236             27.812218   \n",
       " Q2         162.910559          83.104543             64.923798   \n",
       " Q3          30.129734          15.365246             17.854998   \n",
       " Q4         257.723918         219.098707            240.852039   \n",
       " Q5          89.096152          50.710388             55.904292   \n",
       " Q6          99.126137          49.289990             64.797243   \n",
       " Q7         127.746529          72.772159             92.801883   \n",
       " Q8         180.134653         168.557376            189.229889   \n",
       " Q9          62.699387          52.768091             59.910429   \n",
       " Q10         42.271251          14.036328             10.522934   \n",
       " Q11         14.207328           6.853535              3.101577   \n",
       " \n",
       "      orc_st_predicate  \n",
       " Q1          27.536871  \n",
       " Q2          51.144980  \n",
       " Q3           9.889005  \n",
       " Q4         206.814796  \n",
       " Q5          34.386779  \n",
       " Q6          42.472064  \n",
       " Q7          66.980995  \n",
       " Q8         169.538012  \n",
       " Q9          42.285761  \n",
       " Q10          5.073048  \n",
       " Q11          1.129408  ,\n",
       "                          1    2     3     4\n",
       " csv_st_horizontal      0.0  0.0   0.0  11.0\n",
       " avro_st_horizontal     0.0  1.0  10.0   0.0\n",
       " parquet_st_horizontal  3.0  7.0   1.0   0.0\n",
       " orc_st_horizontal      8.0  3.0   0.0   0.0,\n",
       "                          1    2    3     4\n",
       " csv_st_predicate       0.0  0.0  1.0  10.0\n",
       " avro_st_predicate      1.0  6.0  4.0   0.0\n",
       " parquet_st_predicate   0.0  4.0  6.0   1.0\n",
       " orc_st_predicate      10.0  1.0  0.0   0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import xlwings as xw\n",
    "\n",
    "file_format = ['csv', 'avro', 'parquet', 'orc']\n",
    "schemas = ['st', 'vt', 'pt']\n",
    "partition = ['horizontal', 'predicate', 'subject']\n",
    "\n",
    "iterasi = [[[file_format], [schemas], [partition]]]\n",
    "\n",
    "# ST HORIZONTAL\n",
    "li =[]\n",
    "for i in file_format:\n",
    "    df = pd.read_csv(f'./logs/{i}/100M_st_horizontal.txt',sep = ',', header = None)\n",
    "    df = df.fillna(0)\n",
    "    avg = df.mean(axis = 0)\n",
    "    li.append(avg)\n",
    "\n",
    "df1 = pd.DataFrame(li, index=[i + \"_st_horizontal\" for i in file_format])\n",
    "df1 = df1.transpose()\n",
    "# # df = df.set_axis(file_format + \"_st_horizontal\", axis = 1)\n",
    "df1 = df1.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 0)\n",
    "\n",
    "xlwriter = pd.ExcelWriter('~/Desktop/rank_table.xlsx')\n",
    "df.to_excel(xlwriter, 'storage_format_100M')\n",
    "xlwriter.close()\n",
    "\n",
    "# ST PREDICATE\n",
    "xls = pd.ExcelFile(\"~/Desktop/rank_table.xlsx\")\n",
    "df = pd.read_excel(xls, 'storage_format_100M', index_col=0)\n",
    "\n",
    "li=[]\n",
    "for i in file_format:\n",
    "    df = pd.read_csv(f'./logs/{i}/100M_st_predicate.txt',sep = ',', header = None)\n",
    "    df = df.fillna(0)\n",
    "    avg = df.mean(axis = 0)\n",
    "    li.append(avg)\n",
    "\n",
    "df2 = pd.DataFrame(li, index=[i + \"_st_predicate\" for i in file_format])\n",
    "df2 = df2.transpose()         \n",
    "# # df = df.set_axis(file_format + \"_st_horizontal\", axis = 1)\n",
    "df2 = df2.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 0)\n",
    "\n",
    "# CREATE EXCEL\n",
    "dfs = [df1,df2,df1_ranks,df2_ranks]\n",
    "xlwriter = pd.ExcelWriter('~/Desktop/rank_table.xlsx', engine='xlsxwriter')\n",
    "row = 0\n",
    "for dataframe in dfs:\n",
    "        dataframe.to_excel(xlwriter, sheet_name = 'storage_format_100M', startrow = row, startcol = 0)\n",
    "        row = row + len(dataframe.index) + 2 \n",
    "xlwriter.save()\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/csv/100M_horizontal_st.txt\n",
      "./logs/avro/100M_horizontal_st.txt\n",
      "./logs/parquet/100M_horizontal_st.txt\n",
      "./logs/orc/100M_horizontal_st.txt\n",
      "./logs/csv/100M_predicate_st.txt\n",
      "./logs/avro/100M_predicate_st.txt\n",
      "./logs/parquet/100M_predicate_st.txt\n",
      "./logs/orc/100M_predicate_st.txt\n"
     ]
    }
   ],
   "source": [
    "# WRITING THE LOG\n",
    "import pandas as pd\n",
    "file_format = ['csv', 'avro', 'parquet', 'orc']\n",
    "schemas = ['st']\n",
    "partition = ['horizontal','predicate']\n",
    "\n",
    "idx = []\n",
    "li=[]\n",
    "for i in schemas:\n",
    "    for j in partition:\n",
    "        for k in file_format:\n",
    "            #check folder\n",
    "            print(f'./logs/{k}/100M_{j}_{i}.txt')\n",
    "\n",
    "            df = pd.read_csv(f'./logs/{k}/100M_{i}_{j}.txt',sep = ',', header = None)\n",
    "            df = df.fillna(0)\n",
    "            avg = df.mean(axis = 0)\n",
    "            li.append(avg)\n",
    "            idx.append(k + f\"_{i}_{j}\")\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(li, index = [idx])\n",
    "df = df.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 1)\n",
    "# split dataframe\n",
    "dict = {}\n",
    "count = 0\n",
    "loop = 4\n",
    "dfs = []\n",
    "for i in range(len(partition)):\n",
    "    dict['df_{}'.format(i)] = df[count:loop]\n",
    "    count = loop\n",
    "    loop = loop+4\n",
    "    dfs.append(dict[f'df_{i}'])\n",
    "#######################################################################################\n",
    "#CREATE RANK OCCURENCES\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "\n",
    "rank_dataframe = []\n",
    "\n",
    "for x in dfs:\n",
    "    df_ranks = x.T\n",
    "    column_names = df_ranks.columns.to_numpy().tolist()\n",
    "    \n",
    "    df_ranks_occurences = []\n",
    "    for index, row in df_ranks.iterrows():\n",
    "        df_ranks_occurences.append(ss.rankdata(row))\n",
    "\n",
    "    df_ranks_occurences = pd.DataFrame(df_ranks_occurences)\n",
    "\n",
    "    df_transpose = df_ranks_occurences.transpose()\n",
    "\n",
    "    rank_table = []\n",
    "    for index, row in df_transpose.iterrows():\n",
    "        result_row = np.zeros(len(df_transpose.index))\n",
    "        for i in range(len(row)):\n",
    "            result_row[int(row[i])-1] +=1\n",
    "        rank_table.append(result_row)\n",
    "\n",
    "    rank_table = pd.DataFrame(rank_table)\n",
    "    rank_table = rank_table.set_axis(column_names, axis = 'index')\n",
    "    rank_table = rank_table.set_axis([i+1 for i in range(len(column_names))], axis='columns')\n",
    "    rank_dataframe.append(rank_table)\n",
    "#######################################################################################\n",
    "# CREATE EXCEL\n",
    "excel_table = dfs+rank_dataframe\n",
    "xlwriter = pd.ExcelWriter('~/Desktop/rank_table.xlsx', engine='xlsxwriter')\n",
    "row = 0\n",
    "for dataframe in excel_table:\n",
    "        dataframe.to_excel(xlwriter, sheet_name = 'storage_format_100M', startrow = row, startcol = 0)\n",
    "        row = row + len(dataframe.index) + 2 \n",
    "xlwriter.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(li, index = [idx])\n",
    "# df = df.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 1)\n",
    "\n",
    "# # for x in range(2):\n",
    "# #     print(x+1)\n",
    "# #     df+x = df[:4]\n",
    "# # df1 = df[:4]\n",
    "# # df2 = df[4:]\n",
    "# # df2.T\n",
    "\n",
    "# dict = {}\n",
    "# count = 0\n",
    "# loop = 4\n",
    "# dfs = []\n",
    "# for i in range(2):\n",
    "#     dict['df_{}'.format(i)] = df[count:loop].T\n",
    "#     count = loop\n",
    "#     loop = loop+4\n",
    "#     dfs.append(dict[f'df_{i}'])\n",
    "# dfs[2]\n",
    "len(partition)\n",
    "# df1 = pd.DataFrame(li, index=[i + \"_st_horizontal\" for i in file_format])\n",
    "# df1 = df1.transpose()\n",
    "# # # df = df.set_axis(file_format + \"_st_horizontal\", axis = 1)\n",
    "# df1 = df1.set_axis([\"Q\"+str(i+1) for i in range(11)], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANKING TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "\n",
    "rank_dataframe = []\n",
    "\n",
    "for x in dfs:\n",
    "    df_ranks = x.T\n",
    "    column_names = df_ranks.columns.to_numpy().tolist()\n",
    "    \n",
    "    df_ranks_occurences = []\n",
    "    for index, row in df_ranks.iterrows():\n",
    "        df_ranks_occurences.append(ss.rankdata(row))\n",
    "\n",
    "    df_ranks_occurences = pd.DataFrame(df_ranks_occurences)\n",
    "\n",
    "    df_transpose = df_ranks_occurences.transpose()\n",
    "\n",
    "    rank_table = []\n",
    "    for index, row in df_transpose.iterrows():\n",
    "        result_row = np.zeros(len(df_transpose.index))\n",
    "        for i in range(len(row)):\n",
    "            result_row[int(row[i])-1] +=1\n",
    "        rank_table.append(result_row)\n",
    "\n",
    "    rank_table = pd.DataFrame(rank_table)\n",
    "    rank_table = rank_table.set_axis(column_names, axis = 'index')\n",
    "    rank_table = rank_table.set_axis([i+1 for i in range(len(column_names))], axis='columns')\n",
    "    rank_dataframe.append(rank_table)\n",
    "\n",
    "####################################################################################################################\n",
    "# df2_ranks = df2\n",
    "# column_names = df2_ranks.columns.to_numpy().tolist()\n",
    "\n",
    "# df_ranks_occurences = []\n",
    "# for index, row in df2_ranks.iterrows():\n",
    "#     df_ranks_occurences.append(ss.rankdata(row))\n",
    "\n",
    "# df_ranks_occurences = pd.DataFrame(df_ranks_occurences)\n",
    "\n",
    "# df_transpose = df_ranks_occurences.transpose()\n",
    "\n",
    "# df2_ranks = []\n",
    "# for index, row in df_transpose.iterrows():\n",
    "#     result_row = np.zeros(len(df_transpose.index))\n",
    "#     for i in range(len(row)):\n",
    "#         result_row[int(row[i])-1] +=1\n",
    "#     df2_ranks.append(result_row)\n",
    "\n",
    "# df2_ranks = pd.DataFrame(df2_ranks)\n",
    "# df2_ranks\n",
    "# df2_ranks = df2_ranks.set_axis(column_names, axis = 'index')\n",
    "# df2_ranks = df2_ranks.set_axis([i+1 for i in range(len(column_names))], axis='columns')\n",
    "# print(df2_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_table = dfs + rank_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(excel_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f0c97177db804969054b15d96dba8bf61465ec3c27ea998f6ffcddfd8bb05c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('bench-ranking')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
